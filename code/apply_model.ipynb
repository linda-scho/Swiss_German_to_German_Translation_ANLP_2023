{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPNKTbLWps46AbN0SoOhSvw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Apply the models on the Test set"],"metadata":{"id":"T7qZb9EAfxtW"}},{"cell_type":"code","source":["import pandas as pd\n","from tqdm.auto import tqdm, trange\n","from transformers import AutoModelForSeq2SeqLM, NllbTokenizer"],"metadata":{"id":"KR8PMM9nhbeG","executionInfo":{"status":"ok","timestamp":1703098217966,"user_tz":-60,"elapsed":255,"user":{"displayName":"Mira Metzger","userId":"01779271164224279332"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# The project folder can be saved in google drive and accessed through Google colab\n","from google.colab import drive\n","# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RudvEi7KhdK5","executionInfo":{"status":"ok","timestamp":1703097583312,"user_tz":-60,"elapsed":22431,"user":{"displayName":"Mira Metzger","userId":"01779271164224279332"}},"outputId":"fc023ca9-5638-4853-92d4-b67303664e31"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# path to the project folder that contains a folder code, data and models\n","path_project = \"/content/drive/MyDrive/anlp_project/NLLB-200/ANLP_SUBMISSION\""],"metadata":{"id":"-DmSpUVdhxgx","executionInfo":{"status":"ok","timestamp":1703098221805,"user_tz":-60,"elapsed":262,"user":{"displayName":"Mira Metzger","userId":"01779271164224279332"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def translate(text, src_lang, tgt_lang, a=16, b=1.5, max_input_length=1024, **kwargs):\n","    tokenizer.src_lang = src_lang\n","    tokenizer.tgt_lang = tgt_lang\n","    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n","    result = model.generate(\n","        **inputs.to(model.device),\n","        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n","        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n","        **kwargs\n","    )\n","    return tokenizer.batch_decode(result, skip_special_tokens=True)\n","\n","def batched_translate(texts, batch_size=16, **kwargs):\n","    \"\"\"Translate texts in batches of similar length\"\"\"\n","    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n","    results = []\n","    for i in trange(0, len(texts2), batch_size):\n","        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n","    return [p for i, p in sorted(zip(idxs, results))]"],"metadata":{"id":"lpMk_rPRgpcL","executionInfo":{"status":"ok","timestamp":1703098222097,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mira Metzger","userId":"01779271164224279332"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["data_path = f\"{path_project}/data\"\n","\n","df_test = pd.read_csv(f\"{data_path}/df_test.csv\")"],"metadata":{"id":"rBFNbVJ8j4Zr","executionInfo":{"status":"ok","timestamp":1703098224061,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mira Metzger","userId":"01779271164224279332"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["models = {\n","    \"init_none\" : [f\"{path_project}/models/nllb-de-be_initNONE_best_checkpoint\", [\"ch_be\"]],\n","    \"init_vs\" : [f\"{path_project}/models/nllb-de-be_initvs_best_checkpoint\", [\"ch_be\", \"ch_vs\"]],\n","    \"init_gr_large\" : [f\"{path_project}/models/nllb-de-be_initgrLarge_best_checkpoint\", [\"ch_be\", \"ch_gr\"]],\n","    \"init_de\" :[f\"{path_project}/models/nllb-de-be_initde_best_checkpoint\", [\"ch_be\"]],\n","    \"init_average\": [f\"{path_project}/models/nllb-de-be_init_average_v1_best_checkpoint\", [\"ch_be\"]],\n","    \"init_gr_small\": [f\"{path_project}/models/nllb-de-be_initgrSmall_best_checkpoint\", [\"ch_be\", \"ch_gr\"]]\n","}\n","\n","for key, value in models.items():\n","  model_path = f'/content/drive/MyDrive/nlp_project_mira/NLLB-200/{value[0]}'\n","  model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n","  tokenizer = NllbTokenizer.from_pretrained(model_path)\n","\n","  if len(value[1]) == 2:\n","    fix_tokenizer2n(tokenizer, new_lang_tokens=value[1])\n","  elif len(value[1]) == 1:\n","    fix_tokenizer1n(tokenizer, new_lang_token=value[1][0])\n","\n","  df_test[key] = [translate(t, \"ch_be\", 'deu_Latn')[0] for t in tqdm(df_test[\"ch_be\"])]"],"metadata":{"id":"PVxyriRZf0ya","colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"status":"error","timestamp":1703098225821,"user_tz":-60,"elapsed":276,"user":{"displayName":"Mira Metzger","userId":"01779271164224279332"}},"outputId":"95c90503-d6c3-4301-ad24-894b8d042deb"},"execution_count":11,"outputs":[{"output_type":"error","ename":"HFValidationError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-f4cf73da3eee>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/content/drive/MyDrive/nlp_project_mira/NLLB-200/{value[0]}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNllbTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    489\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         ):\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"token\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marg_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;34mf\" '{repo_id}'. Use `repo_type` argument if needed.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/drive/MyDrive/nlp_project_mira/NLLB-200//content/drive/MyDrive/anlp_project/NLLB-200/ANLP_SUBMISSION/models/nllb-de-be_initNONE_best_checkpoint'. Use `repo_type` argument if needed."]}]},{"cell_type":"code","source":["# Filename\n","df_test.to_excel(\"df_test_output_new.xlsx\")"],"metadata":{"id":"pq4eq6jef_pj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Apply the model on the Synthetic Test Set"],"metadata":{"id":"e4NnoN7of4RJ"}},{"cell_type":"code","source":[],"metadata":{"id":"9ECkkceqf53I"},"execution_count":null,"outputs":[]}]}